{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4587bc0-891c-417f-a509-e72d17b9d558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82583e97-893c-433c-9c54-9ff1ed5f13ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4196b054-38ee-463f-9c28-27b37c8acd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Tuple, Optional, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "882243ff-78f5-4688-9250-d70711dd5f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/sofija/Ai4er/mres/tree-segmentation'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"/Users/sofija/Ai4er/mres/tree-segmentation\" )\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86425627-d6e7-42e7-8ba6-079b39acc765",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import TreeSegments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "5a9fc4d2-5cfb-4d4d-b1f9-90f313398cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: \n",
    "\n",
    "#Â does it make any sense to have three (RGB) channels for the depth map? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a75f1e-418b-4cc6-a6d0-def5ef2ce37f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Calculate the mean and standard dev of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c4f07e92-5a8f-4b65-b779-d77b45c24f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "augs = transforms.Compose([transforms.ToTensor(), \n",
    "                           transforms.Normalize(mean = (0, 0, 0),\n",
    "                              std  = (1, 1, 1)),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "328cf001-732e-41dd-a7af-b573874018d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Class defining procedure to load ARCore depth maps\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 depth_dir: str,\n",
    "                 train: bool = True,\n",
    "                 transform: Optional[Callable] = None,):\n",
    "        # Initialize list of relative path to each image\n",
    "        self.depth_paths = [os.path.join(depth_dir, file_name) for file_name in listdir_nohidden(depth_dir)]\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Tuple[Any, Any]:\n",
    "\n",
    "        depth_path = self.depth_paths[idx]\n",
    "        img = Image.open(depth_path)\n",
    "\n",
    "        # Apply transform and return\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img\n",
    "    \n",
    "    def __len__(self):\n",
    "        # Length corresponds to total number of files\n",
    "        return len(self.depth_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "770e1f18-474f-488e-a323-cd514324b548",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = TreeDataset(depth_dir=\"../../data/depths/\", \n",
    "                  transform=augs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "821aceba-c226-4618-b12f-37b6572dd695",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### COMPUTE MEAN / STD\n",
    "\n",
    "# placeholders\n",
    "psum    = torch.tensor([0.0, 0.0, 0.0])\n",
    "psum_sq = torch.tensor([0.0, 0.0, 0.0])\n",
    "\n",
    "# loop through images\n",
    "for i in range(len(ds)):\n",
    "    psum    += ds[i].sum(axis        = [1, 2])\n",
    "    psum_sq += (ds[i] ** 2).sum(axis = [1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c9ad0692-7480-4fd0-aa3b-231b00d5a4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: tensor([0.2860, 0.4530, 0.4528])\n",
      "std:  tensor([0.1852, 0.2681, 0.1247])\n"
     ]
    }
   ],
   "source": [
    "# pixel count\n",
    "count = len(ds) * 120 * 160\n",
    "\n",
    "# mean and std\n",
    "total_mean = psum / count\n",
    "total_var  = (psum_sq / count) - (total_mean ** 2)\n",
    "total_std  = torch.sqrt(total_var)\n",
    "\n",
    "# output\n",
    "print('mean: '  + str(total_mean))\n",
    "print('std:  '  + str(total_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9791d9e-b374-48f8-9c03-6d8a0da76844",
   "metadata": {},
   "source": [
    "## Creating datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24a02e2f-74c0-46c8-bd9c-f10d5a80c896",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datamodules import TreeDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc65d836-e839-483f-9e70-8c005badc847",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = TreeDataModule(data_dir=\"data/depths/\", \n",
    "                   target_dir=\"data/segmented/\",\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0eee9f2-c078-4a50-a08b-1d7d6753d884",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.setup(stage=\"fit\")\n",
    "train_dl = dm.train_dataloader()\n",
    "val_dl = dm.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abe4e8eb-de89-4749-8be5-ab5e387c8807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dm.val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51599fe5-fb0d-4000-a2e0-a3bff23a1106",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in train_dl:\n",
    "    image = sample[0]\n",
    "    mask = sample[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "537ab33f-3aa4-485b-bc3f-fc5d78473fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 3, 120, 160])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5100d96-2834-42c7-b18c-a07a4e205650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18e9b45e-ed09-45cf-8787-b04e3c0e6984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 1, 120, 160])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9da171b-b6b8-4919-a9fb-079b83ccd34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1425c40c-6eb5-466c-bd00-0b8da35c605a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 159.5, 119.5, -0.5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ncols = 2\n",
    "nrows = 1\n",
    "\n",
    "sample_n = 1\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=1,\n",
    "    ncols=ncols,\n",
    "    figsize=(20, ncols * 4),\n",
    ")\n",
    "# permute to rearrange the rgb channel to be last \n",
    "axs[0].imshow(image[sample_n,:,:,:].permute(1, 2, 0))\n",
    "axs[0].axis(\"off\")\n",
    "\n",
    "msk = mask[sample_n, :, :]\n",
    "msk = torch.squeeze(msk)\n",
    "axs[1].imshow(msk)\n",
    "axs[1].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7298d212-d3da-4156-b64d-b5f55d530d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pl_examples.domain_templates.unet import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "74fb7ad7-0935-4c3c-b9a7-fdac00911d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5edfaab3-d9fa-4eac-84a6-6f7b27704819",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â define binary semantic segmentation task lightning module \n",
    "\n",
    "\"\"\"Segmentation tasks.\"\"\"\n",
    "\n",
    "from typing import Any, Dict, cast\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import binary_cross_entropy\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from torch import Tensor\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import Accuracy, JaccardIndex, MetricCollection\n",
    "\n",
    "from pytorch_toolbelt.losses import JaccardLoss, BinaryFocalLoss\n",
    "\n",
    "from torchgeo.datasets.utils import unbind_samples\n",
    "from torchgeo.models import FCN\n",
    "\n",
    "# https://github.com/pytorch/pytorch/issues/60979\n",
    "# https://github.com/pytorch/pytorch/pull/61045\n",
    "DataLoader.__module__ = \"torch.utils.data\"\n",
    "\n",
    "\n",
    "class SemanticSegmentationTask(LightningModule):\n",
    "    \"\"\"LightningModule for semantic segmentation of images.\"\"\"\n",
    "\n",
    "    def config_task(self) -> None:\n",
    "        \"\"\"Configures the task based on kwargs parameters passed to the constructor.\"\"\"\n",
    "        if self.hyperparams[\"segmentation_model\"] == \"unet\":\n",
    "            self.model = smp.Unet(\n",
    "                encoder_name=self.hyperparams[\"encoder_name\"],\n",
    "                encoder_weights=self.hyperparams[\"encoder_weights\"],\n",
    "                in_channels=self.hyperparams[\"in_channels\"],\n",
    "                classes=self.hyperparams[\"num_classes\"],\n",
    "            )\n",
    "        elif self.hyperparams[\"segmentation_model\"] == \"deeplabv3+\":\n",
    "            self.model = smp.DeepLabV3Plus(\n",
    "                encoder_name=self.hyperparams[\"encoder_name\"],\n",
    "                encoder_weights=self.hyperparams[\"encoder_weights\"],\n",
    "                in_channels=self.hyperparams[\"in_channels\"],\n",
    "                classes=self.hyperparams[\"num_classes\"],\n",
    "            )\n",
    "        elif self.hyperparams[\"segmentation_model\"] == \"fcn\":\n",
    "            self.model = FCN(\n",
    "                in_channels=self.hyperparams[\"in_channels\"],\n",
    "                classes=self.hyperparams[\"num_classes\"],\n",
    "                num_filters=self.hyperparams[\"num_filters\"],\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Model type '{self.hyperparams['segmentation_model']}' is not valid.\"\n",
    "            )\n",
    "\n",
    "        if self.hyperparams[\"loss\"] == \"bce\":\n",
    "            self.loss = nn.BCELoss()\n",
    "            \n",
    "#         elif self.hyperparams[\"loss\"] == \"jaccard\":\n",
    "            \n",
    "#             self.losst = JaccardLoss(\n",
    "            \n",
    "#             )\n",
    "            \n",
    "#             self.loss = smp.losses.JaccardLoss(\n",
    "#                 mode=\"multiclass\", classes=self.hyperparams[\"num_classes\"]\n",
    "#             )\n",
    "#         elif self.hyperparams[\"loss\"] == \"focal\":\n",
    "            \n",
    "#             self.loss = BinaryFocalLoss(\n",
    "#             )\n",
    "            \n",
    "            # self.loss = smp.losses.FocalLoss(\n",
    "            #     \"multiclass\", ignore_index=self.ignore_zeros, normalized=True\n",
    "            # )\n",
    "        else:\n",
    "            raise ValueError(f\"Loss type '{self.hyperparams['loss']}' is not valid.\")\n",
    "\n",
    "    def __init__(self, **kwargs: Any) -> None:\n",
    "        \"\"\"Initialize the LightningModule with a model and loss function.\n",
    "        Keyword Args:\n",
    "            segmentation_model: Name of the segmentation model type to use\n",
    "            encoder_name: Name of the encoder model backbone to use\n",
    "            encoder_weights: None or \"imagenet\" to use imagenet pretrained weights in\n",
    "                the encoder model\n",
    "            in_channels: Number of channels in input image\n",
    "            num_classes: Number of semantic classes to predict\n",
    "            loss: Name of the loss function\n",
    "            ignore_zeros: Whether to ignore the \"0\" class value in the loss and metrics\n",
    "        Raises:\n",
    "            ValueError: if kwargs arguments are invalid\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Creates `self.hparams` from kwargs\n",
    "        self.save_hyperparameters()  # type: ignore[operator]\n",
    "        self.hyperparams = cast(Dict[str, Any], self.hparams)\n",
    "\n",
    "        self.ignore_zeros = None if kwargs[\"ignore_zeros\"] else 0\n",
    "\n",
    "        self.config_task()\n",
    "\n",
    "        self.train_metrics = MetricCollection(\n",
    "            [\n",
    "                Accuracy(\n",
    "                    num_classes=self.hyperparams[\"num_classes\"],\n",
    "                    ignore_index=self.ignore_zeros,\n",
    "                ),\n",
    "                # JaccardIndex(\n",
    "                #     num_classes=self.hyperparams[\"num_classes\"],\n",
    "                #     ignore_index=self.ignore_zeros,\n",
    "                # ),\n",
    "            ],\n",
    "            prefix=\"train_\",\n",
    "        )\n",
    "        self.val_metrics = self.train_metrics.clone(prefix=\"val_\")\n",
    "        self.test_metrics = self.train_metrics.clone(prefix=\"test_\")\n",
    "\n",
    "    def forward(self, *args: Any, **kwargs: Any) -> Any:\n",
    "        \"\"\"Forward pass of the model.\n",
    "        Args:\n",
    "            x: tensor of data to run through the model\n",
    "        Returns:\n",
    "            output from the model\n",
    "        \"\"\"\n",
    "        return self.model(*args, **kwargs)\n",
    "\n",
    "    def training_step(self, *args: Any, **kwargs: Any) -> Tensor:\n",
    "        \"\"\"Compute and return the training loss.\n",
    "        Args:\n",
    "            batch: the output of your DataLoader\n",
    "        Returns:\n",
    "            training loss\n",
    "        \"\"\"\n",
    "        batch = args[0]\n",
    "        x = batch[\"image\"]\n",
    "        y = batch[\"mask\"]\n",
    "        y_hat = self.forward(x)\n",
    "        y_hat_hard = y_hat.argmax(dim=1)\n",
    "\n",
    "        loss = self.loss(y_hat, y)\n",
    "\n",
    "        # by default, the train step logs every `log_every_n_steps` steps where\n",
    "        # `log_every_n_steps` is a parameter to the `Trainer` object\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=False)\n",
    "        self.train_metrics(y_hat_hard, y)\n",
    "\n",
    "        return cast(Tensor, loss)\n",
    "\n",
    "    def training_epoch_end(self, outputs: Any) -> None:\n",
    "        \"\"\"Logs epoch level training metrics.\n",
    "        Args:\n",
    "            outputs: list of items returned by training_step\n",
    "        \"\"\"\n",
    "        self.log_dict(self.train_metrics.compute())\n",
    "        self.train_metrics.reset()\n",
    "\n",
    "    def validation_step(self, *args: Any, **kwargs: Any) -> None:\n",
    "        \"\"\"Compute validation loss and log example predictions.\n",
    "        Args:\n",
    "            batch: the output of your DataLoader\n",
    "            batch_idx: the index of this batch\n",
    "        \"\"\"\n",
    "        batch = args[0]\n",
    "        batch_idx = args[1]\n",
    "        x = batch[\"image\"]\n",
    "        y = batch[\"mask\"]\n",
    "        y_hat = self.forward(x)\n",
    "        y_hat_hard = y_hat.argmax(dim=1)\n",
    "\n",
    "        loss = self.loss(y_hat, y)\n",
    "\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True)\n",
    "        self.val_metrics(y_hat_hard, y)\n",
    "\n",
    "        if batch_idx < 10:\n",
    "            try:\n",
    "                datamodule = self.trainer.datamodule  # type: ignore[attr-defined]\n",
    "                batch[\"prediction\"] = y_hat_hard\n",
    "                for key in [\"image\", \"mask\", \"prediction\"]:\n",
    "                    batch[key] = batch[key].cpu()\n",
    "                sample = unbind_samples(batch)[0]\n",
    "                fig = datamodule.plot(sample)\n",
    "                summary_writer = self.logger.experiment\n",
    "                summary_writer.add_figure(\n",
    "                    f\"image/{batch_idx}\", fig, global_step=self.global_step\n",
    "                )\n",
    "            except AttributeError:\n",
    "                pass\n",
    "\n",
    "    def validation_epoch_end(self, outputs: Any) -> None:\n",
    "        \"\"\"Logs epoch level validation metrics.\n",
    "        Args:\n",
    "            outputs: list of items returned by validation_step\n",
    "        \"\"\"\n",
    "        self.log_dict(self.val_metrics.compute())\n",
    "        self.val_metrics.reset()\n",
    "\n",
    "    def test_step(self, *args: Any, **kwargs: Any) -> None:\n",
    "        \"\"\"Compute test loss.\n",
    "        Args:\n",
    "            batch: the output of your DataLoader\n",
    "        \"\"\"\n",
    "        batch = args[0]\n",
    "        x = batch[\"image\"]\n",
    "        y = batch[\"mask\"]\n",
    "        y_hat = self.forward(x)\n",
    "        y_hat_hard = y_hat.argmax(dim=1)\n",
    "\n",
    "        loss = self.loss(y_hat, y)\n",
    "\n",
    "        # by default, the test and validation steps only log per *epoch*\n",
    "        self.log(\"test_loss\", loss, on_step=False, on_epoch=True)\n",
    "        self.test_metrics(y_hat_hard, y)\n",
    "\n",
    "    def test_epoch_end(self, outputs: Any) -> None:\n",
    "        \"\"\"Logs epoch level test metrics.\n",
    "        Args:\n",
    "            outputs: list of items returned by test_step\n",
    "        \"\"\"\n",
    "        self.log_dict(self.test_metrics.compute())\n",
    "        self.test_metrics.reset()\n",
    "\n",
    "    def configure_optimizers(self) -> Dict[str, Any]:\n",
    "        \"\"\"Initialize the optimizer and learning rate scheduler.\n",
    "        Returns:\n",
    "            a \"lr dict\" according to the pytorch lightning documentation --\n",
    "            https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html#configure-optimizers\n",
    "        \"\"\"\n",
    "        optimizer = torch.optim.Adam(\n",
    "            self.model.parameters(), lr=self.hyperparams[\"learning_rate\"]\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": ReduceLROnPlateau(\n",
    "                    optimizer,\n",
    "                    patience=self.hyperparams[\"learning_rate_schedule_patience\"],\n",
    "                ),\n",
    "                \"monitor\": \"val_loss\",\n",
    "            },\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "d7785e59-611e-4fbc-a6fa-d12a985bd937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchgeo.trainers import SemanticSegmentationTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "0efd03fb-5bec-4918-ab05-950e0969db89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SemanticSegmentationTask(\n",
    "        segmentation_model=\"unet\",\n",
    "        encoder_name=\"resnet18\",\n",
    "        # encoder_name=None,\n",
    "        encoder_weights=None,\n",
    "        in_channels=3,\n",
    "        num_classes=1,\n",
    "        # num_filters=32,\n",
    "        loss=\"ce\",\n",
    "        ignore_zeros=True,\n",
    "        learning_rate=0.0001,\n",
    "        learning_rate_schedule_patience=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "8c3db075-7eaa-4dc2-938f-e0908f56fe6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in fast_dev_run mode: will run a full train, val, test and prediction loop using 1 batch(es).\n",
      "`Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
      "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n",
      "`Trainer(limit_test_batches=1)` was configured so 1 batch will be used.\n",
      "`Trainer(limit_predict_batches=1)` was configured so 1 batch will be used.\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    # logger=wandb_logger,\n",
    "    # callbacks=callbacks,\n",
    "    fast_dev_run=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "159a9861-d327-4098-afe8-1d2427ba7b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | model         | Unet             | 14.3 M\n",
      "1 | loss          | CrossEntropyLoss | 0     \n",
      "2 | train_metrics | MetricCollection | 0     \n",
      "3 | val_metrics   | MetricCollection | 0     \n",
      "4 | test_metrics  | MetricCollection | 0     \n",
      "---------------------------------------------------\n",
      "14.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "14.3 M    Total params\n",
      "57.313    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|                                                                                                      | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 16 but got size 15 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [189]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdm\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:768\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;124;03mRuns the full optimization routine.\u001b[39;00m\n\u001b[1;32m    751\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;124;03m    datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\u001b[39;00m\n\u001b[1;32m    766\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m--> 768\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:721\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 721\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;66;03m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[39;00m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:809\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    805\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m ckpt_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_ckpt_path(\n\u001b[1;32m    807\u001b[0m     ckpt_path, model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    808\u001b[0m )\n\u001b[0;32m--> 809\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1234\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mrestore_training_state()\n\u001b[1;32m   1232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mresume_end()\n\u001b[0;32m-> 1234\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1236\u001b[0m log\u001b[38;5;241m.\u001b[39mdetail(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1237\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_teardown()\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1321\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_predict()\n\u001b[0;32m-> 1321\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1351\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1349\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   1350\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1351\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/pytorch_lightning/loops/base.py:204\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:268\u001b[0m, in \u001b[0;36mFitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher\u001b[38;5;241m.\u001b[39msetup(\n\u001b[1;32m    265\u001b[0m     dataloader, batch_to_device\u001b[38;5;241m=\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_call_strategy_hook, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_to_device\u001b[39m\u001b[38;5;124m\"\u001b[39m, dataloader_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    266\u001b[0m )\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 268\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/pytorch_lightning/loops/base.py:204\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py:208\u001b[0m, in \u001b[0;36mTrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_started()\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 208\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# update non-plateau LR schedulers\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;66;03m# update epoch-interval ones only when we are at the end of training epoch\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/pytorch_lightning/loops/base.py:204\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py:88\u001b[0m, in \u001b[0;36mTrainingBatchLoop.advance\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[1;32m     87\u001b[0m     optimizers \u001b[38;5;241m=\u001b[39m _get_active_optimizers(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39moptimizers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39moptimizer_frequencies, batch_idx)\n\u001b[0;32m---> 88\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanual_loop\u001b[38;5;241m.\u001b[39mrun(split_batch, batch_idx)\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/pytorch_lightning/loops/base.py:204\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:203\u001b[0m, in \u001b[0;36mOptimizerLoop.advance\u001b[0;34m(self, batch, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madvance\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch: Any, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m--> 203\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_optimization\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim_progress\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_position\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         \u001b[38;5;66;03m# automatic optimization assumes a loss needs to be returned for extras to be considered as the batch\u001b[39;00m\n\u001b[1;32m    211\u001b[0m         \u001b[38;5;66;03m# would be skipped otherwise\u001b[39;00m\n\u001b[1;32m    212\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_idx] \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39masdict()\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:256\u001b[0m, in \u001b[0;36mOptimizerLoop._run_optimization\u001b[0;34m(self, split_batch, batch_idx, optimizer, opt_idx)\u001b[0m\n\u001b[1;32m    249\u001b[0m         closure()\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    258\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;66;03m# if no result, user decided to skip optimization\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;66;03m# otherwise update running loss + reset accumulated loss\u001b[39;00m\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;66;03m# TODO: find proper way to handle updating running loss\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:369\u001b[0m, in \u001b[0;36mOptimizerLoop._optimizer_step\u001b[0;34m(self, optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_ready()\n\u001b[1;32m    368\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[0;32m--> 369\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopt_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_tpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTPUAccelerator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_native_amp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mamp_backend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mAMPType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNATIVE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_lbfgs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_lbfgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_completed()\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1593\u001b[0m, in \u001b[0;36mTrainer._call_lightning_module_hook\u001b[0;34m(self, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1590\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m hook_name\n\u001b[1;32m   1592\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1593\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1595\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m   1596\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/pytorch_lightning/core/lightning.py:1644\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure, on_tpu, using_native_amp, using_lbfgs)\u001b[0m\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimizer_step\u001b[39m(\n\u001b[1;32m   1563\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1564\u001b[0m     epoch: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1571\u001b[0m     using_lbfgs: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1572\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1573\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1574\u001b[0m \u001b[38;5;124;03m    Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[1;32m   1575\u001b[0m \u001b[38;5;124;03m    each optimizer.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \n\u001b[1;32m   1643\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1644\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py:168\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py:193\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, opt_idx, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"Performs the actual optimizer step.\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \n\u001b[1;32m    185\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m    **kwargs: Any extra arguments to ``optimizer.step``\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m model \u001b[38;5;241m=\u001b[39m model \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py:155\u001b[0m, in \u001b[0;36mPrecisionPlugin.optimizer_step\u001b[0;34m(self, model, optimizer, optimizer_idx, closure, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule):\n\u001b[1;32m    154\u001b[0m     closure \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_closure, model, optimizer, optimizer_idx, closure)\n\u001b[0;32m--> 155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/torch/optim/optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/torch/optim/adam.py:100\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 100\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m    103\u001b[0m     params_with_grad \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py:140\u001b[0m, in \u001b[0;36mPrecisionPlugin._wrap_closure\u001b[0;34m(self, model, optimizer, optimizer_idx, closure)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap_closure\u001b[39m(\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    129\u001b[0m     model: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    132\u001b[0m     closure: Callable[[], Any],\n\u001b[1;32m    133\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m    ``on_before_optimizer_step`` hook is called.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m    The closure (generally) runs ``backward`` so this allows inspecting gradients in this hook. This structure is\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03m    consistent with the ``PrecisionPlugin`` subclasses that cannot pass ``optimizer.step(closure)`` directly.\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m     closure_result \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_closure(model, optimizer, optimizer_idx)\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m closure_result\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:148\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m--> 148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:134\u001b[0m, in \u001b[0;36mClosure.closure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ClosureResult:\n\u001b[0;32m--> 134\u001b[0m     step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step_output\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarning_cache\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`training_step` returned `None`. If this was on purpose, ignore this warning...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:427\u001b[0m, in \u001b[0;36mOptimizerLoop._training_step\u001b[0;34m(self, split_batch, batch_idx, opt_idx)\u001b[0m\n\u001b[1;32m    422\u001b[0m step_kwargs \u001b[38;5;241m=\u001b[39m _build_training_step_kwargs(\n\u001b[1;32m    423\u001b[0m     lightning_module, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39moptimizers, split_batch, batch_idx, opt_idx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hiddens\n\u001b[1;32m    424\u001b[0m )\n\u001b[1;32m    426\u001b[0m \u001b[38;5;66;03m# manually capture logged metrics\u001b[39;00m\n\u001b[0;32m--> 427\u001b[0m training_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_kwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mpost_training_step()\n\u001b[1;32m    430\u001b[0m model_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_step_end\u001b[39m\u001b[38;5;124m\"\u001b[39m, training_step_output)\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1763\u001b[0m, in \u001b[0;36mTrainer._call_strategy_hook\u001b[0;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1762\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1763\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py:333\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;124;03m\"\"\"The actual training step.\u001b[39;00m\n\u001b[1;32m    329\u001b[0m \n\u001b[1;32m    330\u001b[0m \u001b[38;5;124;03mSee :meth:`~pytorch_lightning.core.lightning.LightningModule.training_step` for more details\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mtrain_step_context():\n\u001b[0;32m--> 333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/torchgeo/trainers/segmentation.py:135\u001b[0m, in \u001b[0;36mSemanticSegmentationTask.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m x \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    134\u001b[0m y \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 135\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m y_hat_hard \u001b[38;5;241m=\u001b[39m y_hat\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    138\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(y_hat, y)\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/torchgeo/trainers/segmentation.py:121\u001b[0m, in \u001b[0;36mSemanticSegmentationTask.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;124;03m\"\"\"Forward pass of the model.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \n\u001b[1;32m    115\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m        output from the model\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/segmentation_models_pytorch/base/model.py:16\u001b[0m, in \u001b[0;36mSegmentationModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m\"\"\"Sequentially pass `x` trough model`s encoder, decoder and heads\"\"\"\u001b[39;00m\n\u001b[1;32m     15\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x)\n\u001b[0;32m---> 16\u001b[0m decoder_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m masks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msegmentation_head(decoder_output)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassification_head \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/segmentation_models_pytorch/unet/decoder.py:119\u001b[0m, in \u001b[0;36mUnetDecoder.forward\u001b[0;34m(self, *features)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, decoder_block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks):\n\u001b[1;32m    118\u001b[0m     skip \u001b[38;5;241m=\u001b[39m skips[i] \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(skips) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/trees/lib/python3.9/site-packages/segmentation_models_pytorch/unet/decoder.py:38\u001b[0m, in \u001b[0;36mDecoderBlock.forward\u001b[0;34m(self, x, skip)\u001b[0m\n\u001b[1;32m     36\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39minterpolate(x, scale_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m skip \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention1(x)\n\u001b[1;32m     40\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 16 but got size 15 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "trainer.fit(model=model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2f8103-8e48-4654-ac8e-a9cd9fe95b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
